{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfc270b",
   "metadata": {},
   "source": [
    "# Handling Local Data\n",
    "To load datasets that are stored either on your laptop or on a remote server, we can still use the `load_dataset()` function. This time, we just need to specify the type of loading script in the `load_dataset()` function, along with a `data_files=''` argument that specifies the path to one or more files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99872279",
   "metadata": {},
   "source": [
    "### Loading a local dataset\n",
    "\n",
    "| Data format | Loading script | Example |\n",
    "|-------------|----------------|---------|\n",
    "| CSV & TSV |`csv`|`load_dataset(\"csv\", data_files=\"my_file.csv\")`|\n",
    "| Text files |`text`|`load_dataset(\"text\", data_files=\"my_file.txt\")`|\n",
    "| JSON & JSON Lines |`json`|`load_dataset(\"json\", data_files=\"my_file.json\")`|\n",
    "| Pickled DataFrames |`pandas`|`load_dataset(\"pandas\", data_files=\"my_dataframe.pkl\")`|\n",
    "\n",
    "For this example, let's use the [SQuAD-it](https://github.com/crux82/squad-it/) dataset, which is a large-scale **json** dataset for question answering in Italian. It's hosted on GitHub, let's first download it in our `data/chapter_5` dir using `wget` and then decompress these compressed files `SQuAD_it-train.json.gz`, `SQuAD_it-test.json.gz` using `gzip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef67e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd data/chapter_5 && wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz\n",
    "!cd data/chapter_5 && wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz\n",
    "\n",
    "!cd data/chapter_5 && gzip -dkv SQuAD_it-*.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfbe4aa",
   "metadata": {},
   "source": [
    "Now that we have our data in the `JSON` format, we can simply use the `load_dataset()` function, we just need to know if we’re dealing with **ordinary JSON** (*similar to a nested dictionary*) or **JSON Lines** (*line-separated JSON*). Like many question answering datasets, **SQuAD-it** uses the *nested format*, with all the text stored in a **data field**. This means we can load the dataset by specifying the `field='data'` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102036ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=\"data/chapter_5/SQuAD_it-train.json\", field=\"data\")\n",
    "\n",
    "squad_it_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c461d993",
   "metadata": {},
   "source": [
    "As we can see, by default, loading local files creates a `DatasetDict` object with only a **train** split. But, what we really want is to include both the **train** and **test** splits in a single `DatasetDict` object so we can apply `Dataset.map()` functions across both splits at once. To do this, we can provide a dictionary to the \n",
    "```python\n",
    "data_files={\"train\":\"path to the training data\", \"test\":\"path to the testing data\"}\n",
    "```\n",
    "argument that maps each split name to a file associated with that split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc636f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train\":\"data/chapter_5/SQuAD_it-train.json\",\n",
    "    \"test\":\"data/chapter_5/SQuAD_it-test.json\"\n",
    "}\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\n",
    "squad_it_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb86667",
   "metadata": {},
   "source": [
    "The loading scripts in Datasets actually support automatic decompression of the input files, so we could have skipped the use of gzip by pointing the `data_files` argument directly to the compressed files:\n",
    "```python\n",
    "data_files = {\n",
    "    \"train\": \"data/chapter_5/SQuAD_it-train.json.gz\", \n",
    "    \"test\": \"data/chapter_5/SQuAD_it-test.json.gz\"\n",
    "}\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\n",
    "```\n",
    "This can be useful if you don’t want to manually decompress many `GZIP` files. The automatic decompression also applies to other common formats like `ZIP` and `TAR`, so you just need to point `data_files` to the compressed files.\n",
    "\n",
    "> The `data_files` argument is also quite flexible and can be either *a single file path*, *a list of file paths*, or *a dictionary* that maps split names to file paths. You can also *glob files* that match a *specified pattern* according to the rules used by the `Unix shell` (e.g., you can glob all the `JSON` files in a directory as a single split by setting `data_files=\"*.json\"`). See the [Datasets documentation](https://huggingface.co/docs/datasets/loading#local-and-remote-files) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5facc",
   "metadata": {},
   "source": [
    "### Loading a remote dataset\n",
    "\n",
    "Fortunately, loading *remote files* is just as simple as loading *local* ones!\n",
    "<br />\n",
    "Instead of providing a path to *local files*, we point the `data_files` argument to **one or more URLs** where the *remote files* are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf78445",
   "metadata": {},
   "outputs": [],
   "source": [
    "url =  \"https://github.com/crux82/squad-it/raw/master/\"\n",
    "\n",
    "data_files = {\n",
    "    \"train\": url + \"SQuAD_it-train.json.gz\",\n",
    "    \"test\": url + \"SQuAD_it-test.json.gz\",\n",
    "}\n",
    "\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\n",
    "squad_it_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
